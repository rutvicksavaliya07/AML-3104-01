{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023F-T3_AML 3104_01 - Assignment 03 \n",
    "### Rutvick Savaliya - C0865187"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q1. Describe the decision tree classifier algorithm and how it works to make predictions:- </h3>\n",
    "\n",
    "Decision Tree is a tree-structured classifier that is used for both classification and regression problems. It is a supervised learning technique that is mostly preferred for solving classification problems.\n",
    "In a Decision tree, internal nodes represent the features of a dataset, branches represent the decision rules, and each leaf node represents the outcome. \n",
    "The decisions or the test are performed on the basis of features of the given dataset. \n",
    "It is called a decision tree because, similar to a tree, it starts with the root node, which expands on further branches and constructs a tree-like structure. \n",
    "CART algorithm, which stands for Classification and Regression Tree algorithm, is used to build a tree. \n",
    "A decision tree simply asks a question, and based on the answer (Yes/No), it further splits the tree into subtrees.\n",
    "\n",
    "In a decision tree, the algorithm starts from the root node of the tree to predict the class of the given dataset. It compares the values of the root attribute with the record attribute and, based on the comparison, follows the branch and jumps to the next node. The algorithm then compares the attribute value with the other sub-nodes and moves further. It continues the process until it reaches the leaf node of the tree. The complete process can be better understood using the following algorithm:\n",
    "\n",
    "1. Begin the tree with the root node, S, which contains the complete dataset.\n",
    "2. Find the best attribute in the dataset using Attribute Selection Measure (ASM).\n",
    "3. Divide S into subsets that contain possible values for the best attributes.\n",
    "4. Generate the decision tree node, which contains the best attribute.\n",
    "5. Recursively make new decision trees using the subsets of the dataset created in step 3. Continue this process until a stage is reached where you cannot further classify the nodes and call the final node a leaf node.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification.</h3>\n",
    "\n",
    "Decision tree classification is a machine learning algorithm that is used for both classification and regression tasks. It works by recursively partitioning the input data into subsets, with the goal of creating a tree-like structure to make decisions or predictions. Here's a step-by-step explanation of the mathematical intuition behind decision tree classification:\n",
    "\n",
    "1. Start with the entire dataset: At the root of the decision tree, you begin with the entire dataset, which consists of a set of features (input variables) and a target variable (the class label you want to predict). In the case of classification, the target variable represents the classes or categories that the data points belong to.\n",
    "\n",
    "2. Select the best feature to split the data: The algorithm evaluates each feature to determine the best feature to split the data into subsets. It does this by calculating a measure of impurity or information gain for each feature. Common impurity measures for classification trees include Gini impurity and entropy.\n",
    "\n",
    "    Gini Impurity: Gini impurity measures the probability of misclassifying a randomly chosen element if it were classified based on the distribution of the target classes in the subset. A lower Gini impurity indicates purer subsets.\n",
    "    \n",
    "    Entropy: Entropy measures the amount of disorder or randomness in a subset. A lower entropy indicates more ordered, or \"pure,\" subsets.\n",
    "\n",
    "3. Split the data based on the selected feature: Once the best feature is selected, the data is divided into subsets based on the values of that feature. Each subset corresponds to a branch of the decision tree. For each unique value of the selected feature, a branch is created.\n",
    "\n",
    "4. Repeat the process recursively: Steps 2 and 3 are repeated recursively for each subset created. The algorithm continues to select the best feature to split each subset until a stopping condition is met. This condition could be a maximum depth limit, a minimum number of samples required to split a node, or a minimum improvement in impurity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q3. Explain how a decision tree classifier can be used to solve a binary classification problem.</h3>\n",
    "\n",
    "A decision tree classifier can be used to solve a binary classification problem by dividing the dataset into two distinct classes or categories. In binary classification, you are typically trying to classify data points into one of two possible classes, often denoted as \"positive\" and \"negative,\" \"yes\" and \"no,\" \"spam\" and \"not spam,\" or any other two distinct labels. Here's how a decision tree classifier accomplishes this:\n",
    "\n",
    "Data Preparation: You start with a dataset that contains features (input variables) and a target variable that represents the binary classes. Each data point in the dataset has a feature vector and a corresponding class label, which can be 0 (negative class) or 1 (positive class).\n",
    "\n",
    "Decision Tree Construction: The decision tree classifier begins by evaluating the features in the dataset to determine the best feature to split the data into two subsets. This decision is based on impurity measures like Gini impurity or entropy. The goal is to choose the feature and split that minimizes impurity or maximizes information gain.\n",
    "\n",
    "Splitting the Data: The dataset is divided into two subsets based on the selected feature. One subset will contain data points where the feature value satisfies the chosen split condition, and the other subset contains data points where the feature value does not satisfy the condition. This effectively separates the data into two categories, one corresponding to the positive class and the other to the negative class.\n",
    "\n",
    "Repeat Recursively: The algorithm repeats steps 2 and 3 recursively for each subset created by the splits. It continues to select features and perform splits until a stopping condition is met, such as a maximum tree depth, a minimum number of samples in a leaf node, or other criteria.\n",
    "\n",
    "Assigning Class Labels: Once the decision tree is constructed, the leaf nodes represent subsets of the data. For binary classification, these leaf nodes are assigned class labels based on the majority class within each leaf. In other words, if a leaf node contains more data points from the positive class, it will be assigned the positive class label (1); if it contains more data points from the negative class, it will be assigned the negative class label (0).\n",
    "\n",
    "Making Predictions: To make predictions for new, unseen data points, you start at the root of the decision tree and follow the branches by comparing the feature values of the data point to the feature values used in the splits. You move down the tree until you reach a leaf node, and the class label assigned to that leaf node is your prediction. In binary classification, this will be either 0 or 1, representing the predicted class.\n",
    "\n",
    "The decision tree classifier leverages the hierarchical structure of the tree to make binary classification decisions by successively splitting the data based on the most informative features. It assigns class labels to the leaf nodes, which are used to classify new data points. This process is guided by mathematical measures of impurity or information gain, ensuring that the tree optimally separates the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make\n",
    "predictions.</h3>\n",
    "\n",
    "Decision trees are one of the most essential concepts in modern machine learning. They are not only a good solution \n",
    "for classification and regression issues, but they are also the foundation for more complicated algorithms like as random \n",
    "forests and gradient boosting.It is based on a hierarchical structure that represents a set of rules used to make decisions about the class labels of data points. The geometric intuition behind decision tree classification can be understood by considering how a decision tree divides the feature space into regions associated with different class labels.\n",
    "Below is a simple decision tree of an IRIS Data\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*6wfIL1heS2_BMOyBeA49dw.png\"/>\n",
    "\n",
    "Letâ€™s see how we can represent the same decision tree geometrically.\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*wvyXSrZSQso_h0pdY9BkYg.png\"/>\n",
    "\n",
    "Here's the geometric intuition behind decision tree classification:\n",
    "1. Feature Space Partitioning:\n",
    "Think of the feature space as a multi-dimensional space where each dimension corresponds to a feature (e.g., age, income, temperature, etc.).\n",
    "At the root of the decision tree, the entire feature space represents the initial region.\n",
    "Each internal node of the tree corresponds to a decision point or a split on a specific feature. It divides the current region into two or more subregions based on the feature's values.\n",
    "\n",
    "2. Recursive Splitting:\n",
    "As you traverse down the tree from the root to the leaves, you encounter more decision points (internal nodes) that further partition the space.\n",
    "Each decision point defines a boundary in the feature space based on a feature's value. For example, if you're classifying people into \"yes\" or \"no\" for a loan application, one decision point might be income > $50,000.\n",
    "\n",
    "3. Leaf Nodes and Class Labels:\n",
    "The terminal nodes of the decision tree are called leaf nodes. Each leaf node is associated with a specific class label.\n",
    "When you reach a leaf node, it means you've reached a decision, and the associated class label is assigned to the data point that reached that leaf.\n",
    "\n",
    "4. Decision Boundaries:\n",
    "The decision boundaries are the regions in the feature space where the class labels are determined.\n",
    "These boundaries are orthogonal to the feature axes and depend on the decision points along the path from the root to the leaf nodes.\n",
    "5. Geometric Interpretation:\n",
    "The decision tree's geometric structure can be visualized as a series of nested rectangles (for 2D features) or hyperplanes (for higher dimensions) that partition the feature space.\n",
    "Each split corresponds to a division of the feature space into two or more smaller regions, and this division continues until a leaf node is reached.\n",
    "\n",
    "To make predictions using a decision tree, you start at the root node and follow the path down the tree based on the feature values of the data point you want to classify. You traverse the tree until you reach a leaf node, which provides the predicted class label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a\n",
    "classification model </h3>\n",
    "\n",
    "A confusion matrix is a fundamental tool for evaluating the performance of a classification model. It provides a summary of the model's predictions and how well it classifies instances into different categories or classes. The confusion matrix is particularly useful in assessing the quality of a classification model by comparing its predictions with the actual outcomes.\n",
    "\n",
    "A confusion matrix is typically organized into a 2x2 table (for binary classification) or a larger matrix (for multi-class classification), with the following components:\n",
    "\n",
    "1. True Positives (TP): These are the cases where the model correctly predicted a positive outcome (e.g., correctly identified a disease in a medical diagnosis).\n",
    "\n",
    "2. True Negatives (TN): These are the cases where the model correctly predicted a negative outcome (e.g., correctly identified the absence of a disease in a medical diagnosis).\n",
    "\n",
    "3. False Positives (FP): These are the cases where the model incorrectly predicted a positive outcome when it should have been negative (e.g., incorrectly diagnosing a healthy person as having a disease).\n",
    "\n",
    "4. False Negatives (FN): These are the cases where the model incorrectly predicted a negative outcome when it should have been positive (e.g., failing to diagnose a person with a disease).\n",
    "\n",
    "Here's how a confusion matrix can be used to evaluate the performance of a classification model:\n",
    "\n",
    "1. **Accuracy**: Accuracy is a commonly used metric and is calculated as (TP + TN) / (TP + TN + FP + FN). It measures the overall correctness of the model's predictions.\n",
    "\n",
    "2. **Precision (Positive Predictive Value)**: Precision is calculated as TP / (TP + FP). It measures the model's ability to correctly identify positive cases without making too many false positive predictions. It is crucial when the cost of false positives is high.\n",
    "\n",
    "3. **Recall (Sensitivity, True Positive Rate)**: Recall is calculated as TP / (TP + FN). It measures the model's ability to correctly identify all positive cases, minimizing false negatives. It is important when missing positive cases is costly.\n",
    "\n",
    "4. **Specificity (True Negative Rate)**: Specificity is calculated as TN / (TN + FP). It measures the model's ability to correctly identify negative cases, minimizing false positive predictions.\n",
    "\n",
    "5. **F1-Score**: The F1-Score is the harmonic mean of precision and recall and is calculated as 2 * (Precision * Recall) / (Precision + Recall). It provides a balance between precision and recall, making it suitable when you need to consider both false positives and false negatives.\n",
    "\n",
    "6. **Area Under the ROC Curve (AUC-ROC)**: The ROC curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold values. The AUC-ROC measures the model's ability to discriminate between positive and negative cases across different thresholds.\n",
    "\n",
    "7. **Area Under the Precision-Recall Curve (AUC-PR)**: The precision-recall curve plots precision against recall for different threshold values. AUC-PR measures the model's ability to balance precision and recall across different threshold settings.\n",
    "\n",
    "The choice of which metrics to prioritize depends on the specific problem and the relative importance of false positives and false negatives. For example, in medical diagnoses, you might prioritize recall to minimize false negatives, even if it means accepting more false positives. In fraud detection, you may prioritize precision to reduce false positives, even if it results in some missed fraud cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be\n",
    "calculated from it. </h3>\n",
    "\n",
    "                       |    Spam (Positive)  |  Not Spam (Negative) |\n",
    "        Actual Class   |    \t120 (TP)     |     30 (FP)          |   \n",
    "        Predicted Class| \t    20 (FN)     |     830 (TN)         | \n",
    "\n",
    "\n",
    "\n",
    "In this confusion matrix:\n",
    "    True Positives (TP): 120 - The model correctly predicted 120 emails as spam.\n",
    "    False Positives (FP): 30 - The model incorrectly predicted 30 emails as spam when they were not.\n",
    "    False Negatives (FN): 20 - The model incorrectly predicted 20 emails as not spam when they were actually spam.\n",
    "    True Negatives (TN): 830 - The model correctly predicted 830 emails as not spam.\n",
    "\n",
    "Now, let's calculate Precision, Recall, and F1 Score based on this confusion matrix:\n",
    "    \n",
    "Precision:\n",
    "Precision measures the accuracy of the positive predictions. It's the ratio of true positives to the sum of true positives and false positives.\n",
    "Precision = TP / (TP + FP) = 120 / (120 + 30) = 0.8 (or 80%)\n",
    "A precision of 80% means that out of all the emails predicted as spam, 80% were indeed spam.\n",
    "\n",
    "Recall:\n",
    "    Recall (also known as Sensitivity or True Positive Rate) measures the model's ability to correctly identify all positive instances. It's the ratio of true positives to the sum of true positives and false negatives.\n",
    "Recall = TP / (TP + FN) = 120 / (120 + 20) = 0.857 (or 85.7%)\n",
    "A recall of 85.7% means that the model correctly identified 85.7% of all the actual spam emails.\n",
    "\n",
    "F1 Score:\n",
    "The F1 Score is the harmonic mean of precision and recall, providing a balanced measure that takes into account false positives and false negatives.\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall) = 2 * (0.8 * 0.857) / (0.8 + 0.857) = 0.828 (or 82.8%)\n",
    "The F1 Score of 82.8% combines both precision and recall into a single metric, which is useful when you want to balance the trade-off between these two aspects of classification performance.\n",
    "\n",
    "These metrics can help you assess the model's effectiveness in classifying spam emails, taking into account both the accuracy of spam predictions (precision) and the ability to catch most spam emails (recall). The specific thresholds for these metrics can be adjusted depending on the application's requirements and the relative importance of false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and\n",
    "explain how this can be done.</h3>\n",
    "\n",
    "Choosing an appropriate evaluation metric for a classification problem is crucial because it allows you to assess how well your machine learning model is performing and whether it meets the specific goals of your project. The choice of metric can significantly impact your model selection, hyperparameter tuning, and overall decision-making process. Different evaluation metrics are suited for different types of classification problems, and they prioritize various aspects of model performance. Let's discuss the importance and how to choose an appropriate evaluation metric with a Python program.\n",
    "\n",
    "Importance of Choosing the Right Metric:\n",
    "\n",
    "Understanding Model Performance: Evaluation metrics provide insights into how well your model is doing. It helps you gauge the model's accuracy, effectiveness, and its ability to generalize to new, unseen data.\n",
    "\n",
    "Alignment with Business Goals: The choice of the metric should align with the specific objectives of your project. Different applications may require different priorities, such as minimizing false positives, maximizing true positives, or achieving a balance between precision and recall.\n",
    "\n",
    "Handling Class Imbalance: In imbalanced datasets where one class has significantly more instances than the other, choosing the right metric can help you avoid being misled by a high accuracy rate. Metrics like precision, recall, and F1-score are more appropriate in such cases.\n",
    "\n",
    "Model Comparison: When comparing different models or variations of a model, using the same evaluation metric allows for a fair and meaningful comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q8. Provide an example of a classification problem where precision is the most important metric, and\n",
    "explain why.</h3>\n",
    "\n",
    "A common example of a classification problem where precision is the most important metric is in medical diagnosis, particularly in the context of detecting diseases or medical conditions. Let's take the example of a diagnostic test for a rare and life-threatening disease, such as a specific type of cancer.\n",
    "\n",
    "Example: Detecting a Rare Cancer\n",
    "\n",
    "In this scenario, precision is the most important metric for the following reasons:\n",
    "\n",
    "Consequences of False Positives: False positives, in this context, mean that a healthy individual is misdiagnosed as having the disease. This could lead to unnecessary stress, further medical tests, and potentially harmful treatments. In the case of invasive treatments like surgery or chemotherapy, the consequences could be severe.\n",
    "\n",
    "Rare Disease: The disease in question is rare, which means that the majority of people tested will not have it. In such cases, even a small number of false positives can greatly outnumber the true positives, making precision crucial for ensuring that those who receive a positive diagnosis are highly likely to actually have the disease.\n",
    "\n",
    "Treatment and Resources: The treatment for this specific cancer may be expensive, invasive, and come with significant side effects. Therefore, it's crucial to avoid unnecessary treatment for patients who do not have the disease. Precision ensures that the resources are allocated efficiently to those who truly need them.\n",
    "\n",
    "Trust and Patient Well-Being: Misdiagnosing healthy individuals can lead to a loss of trust in the medical system and harm the psychological well-being of patients. Ensuring high precision helps maintain trust in the medical profession.\n",
    "\n",
    "A sample program is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9459459459459459\n",
      "Recall: 0.9859154929577465\n",
      "F1-Score: 0.9655172413793103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshay\\Desktop\\Courses\\ZTM\\sample_project\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the Breast Cancer Wisconsin dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q9. Provide an example of a classification problem where recall is the most important metric and explain\n",
    "why</h3>\n",
    "\n",
    "A typical example of a classification problem where recall is the most important metric is in the context of email spam detection. In this scenario, the goal is to identify as many spam emails as possible (high recall) while allowing some non-spam emails to be incorrectly classified as spam (potentially lower precision). Let's delve into this example and provide some Python code to illustrate it.\n",
    "\n",
    "Example: Email Spam Detection\n",
    "\n",
    "In email spam detection, recall is more important than precision for the following reasons:\n",
    "\n",
    "Consequences of Missing Spam Emails: Missing a few spam emails (false negatives) is generally less harmful than letting them reach the user's inbox. Spam emails may contain phishing attempts, malware, or other malicious content, which can lead to security risks, privacy breaches, or financial losses.\n",
    "\n",
    "User Experience: False positives (genuine emails classified as spam) can be annoying to users, but they are typically less harmful than missing important emails. Users can manually review their spam folders to rescue legitimate emails, but they may not even be aware of the potentially harmful emails that were missed.\n",
    "\n",
    "Class Imbalance: In email datasets, spam emails are often a minority class compared to legitimate emails. Maximizing recall ensures that the majority of spam emails are correctly identified, even if it means a higher number of false positives.\n",
    "\n",
    "Resource Allocation: Allocating resources to further investigate or filter out potential spam emails (even if they are false positives) is usually an acceptable trade-off to ensure a high recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8333333333333334\n",
      "Recall: 1.0\n",
      "F1-Score: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Simulated ground truth labels (0: Legitimate Email, 1: Spam)\n",
    "true_labels = [0, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
    "# Simulated model predictions (1: Predicted spam)\n",
    "predicted_labels = [0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
